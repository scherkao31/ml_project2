{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c864a3de",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 40 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Load Librairies </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f99a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\ada\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a030cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxim\\anaconda3\\envs\\ada\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 127] La procédure spécifiée est introuvable\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2648bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conf_matrix\n",
    "from conf_matrix import make_confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb7233",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 40px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-danger\">1 |</span></b> Load the data </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3702970",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL = \"data/original_data/\"\n",
    "TRAIN_DIR = ORIGINAL + \"mut_effect_train.csv\"\n",
    "TEST_DIR = ORIGINAL + \"mut_effect_test.csv\"\n",
    "VAL_DIR =  ORIGINAL + \"mut_effect_validation.csv\"\n",
    "UNIPROT_DIR = ORIGINAL + \"uniprot_fasta_sequences.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346b334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_effect_train = pd.read_csv(TRAIN_DIR)\n",
    "mut_effect_test = pd.read_csv(TEST_DIR)\n",
    "mut_effect_val = pd.read_csv(VAL_DIR)\n",
    "\n",
    "uniprot_seq = pd.read_csv(UNIPROT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96d437",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 30px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-success\"> Exploration of the data</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0164b7",
   "metadata": {},
   "source": [
    "\n",
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">1.1.1 |</span></b> Display the original data  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c537f",
   "metadata": {},
   "source": [
    "mut_effect_train, mut_effect_test and mut_effect_test have the same structure. They formed the dataset already divided in three distincts parts : training, testing, validation. \n",
    "Here we display the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ac6809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot</th>\n",
       "      <th>ftype</th>\n",
       "      <th>pos</th>\n",
       "      <th>ori_res</th>\n",
       "      <th>var_res</th>\n",
       "      <th>desc</th>\n",
       "      <th>no effect</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2G160</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>165</td>\n",
       "      <td>K</td>\n",
       "      <td>C</td>\n",
       "      <td>3125-fold decrease in catalytic activity, and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O33599</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>117</td>\n",
       "      <td>N</td>\n",
       "      <td>A</td>\n",
       "      <td>Activates the enzyme.</td>\n",
       "      <td>False</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O33599</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>210</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>Inactivates the enzyme.</td>\n",
       "      <td>False</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O33599</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>214</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>Inactivates the enzyme.</td>\n",
       "      <td>False</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O33599</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>291</td>\n",
       "      <td>H</td>\n",
       "      <td>A</td>\n",
       "      <td>Inactivates the enzyme.</td>\n",
       "      <td>False</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46387</th>\n",
       "      <td>C6KT50</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>139</td>\n",
       "      <td>R</td>\n",
       "      <td>A</td>\n",
       "      <td>No activity; when associated with A-136 and A-...</td>\n",
       "      <td>False</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46388</th>\n",
       "      <td>C6KT50</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>140</td>\n",
       "      <td>R</td>\n",
       "      <td>A</td>\n",
       "      <td>No activity; when associated with A-136 and A-...</td>\n",
       "      <td>False</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46389</th>\n",
       "      <td>C6KT50</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>151</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>No activity. The mutant forms hexamers instead...</td>\n",
       "      <td>False</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46390</th>\n",
       "      <td>Q8ILG2</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>246</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>Loss of catalytic activity.</td>\n",
       "      <td>False</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46391</th>\n",
       "      <td>Q8IJP2</td>\n",
       "      <td>mutagenesis site</td>\n",
       "      <td>316</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>50% reduction in activity with Zn(2+) as cofac...</td>\n",
       "      <td>False</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniprot             ftype  pos ori_res var_res  \\\n",
       "0      Q2G160  mutagenesis site  165       K       C   \n",
       "1      O33599  mutagenesis site  117       N       A   \n",
       "2      O33599  mutagenesis site  210       H       A   \n",
       "3      O33599  mutagenesis site  214       D       A   \n",
       "4      O33599  mutagenesis site  291       H       A   \n",
       "...       ...               ...  ...     ...     ...   \n",
       "46387  C6KT50  mutagenesis site  139       R       A   \n",
       "46388  C6KT50  mutagenesis site  140       R       A   \n",
       "46389  C6KT50  mutagenesis site  151       K       A   \n",
       "46390  Q8ILG2  mutagenesis site  246       D       A   \n",
       "46391  Q8IJP2  mutagenesis site  316       C       S   \n",
       "\n",
       "                                                    desc  no effect  length  \n",
       "0      3125-fold decrease in catalytic activity, and ...      False     293  \n",
       "1                                  Activates the enzyme.      False     316  \n",
       "2                                Inactivates the enzyme.      False     316  \n",
       "3                                Inactivates the enzyme.      False     316  \n",
       "4                                Inactivates the enzyme.      False     316  \n",
       "...                                                  ...        ...     ...  \n",
       "46387  No activity; when associated with A-136 and A-...      False     301  \n",
       "46388  No activity; when associated with A-136 and A-...      False     301  \n",
       "46389  No activity. The mutant forms hexamers instead...      False     301  \n",
       "46390                        Loss of catalytic activity.      False     627  \n",
       "46391  50% reduction in activity with Zn(2+) as cofac...      False     517  \n",
       "\n",
       "[46392 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mut_effect_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22137f1b",
   "metadata": {},
   "source": [
    "The uniprot data contains the correspondences between the uniprot code of the studied proteins and their sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a841e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K0F8Z5</td>\n",
       "      <td>MSSEKIQRVGIIGAGQMGAGIAEVCARAHVDVLVYEQTRELAAAGR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K0F1Z7</td>\n",
       "      <td>MTRHVDVLIIGAGLSGIGMACHLTREQTGRSYAILERRAAIGGTWD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K0EI02</td>\n",
       "      <td>MPKARATALITAALIVVVLVAGCTRLVDGRAVSIYDDPFKVAGLPT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K0EPK0</td>\n",
       "      <td>MYSPIEDWDTDEVWMFLMQYANPWGVSNKDLLTMYQGASADSECPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0EQ80</td>\n",
       "      <td>MTEASADAAGARRRRNRDIAGRHVLITGASSGIGRAAAIAVAGKGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561557</th>\n",
       "      <td>A0A1C1CCI4</td>\n",
       "      <td>MGSIPSDQAVAPPPSTTTYNIASIPADGIGPEVITAGINVLNTLSR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561558</th>\n",
       "      <td>A0A1C1D2I0</td>\n",
       "      <td>MEMQLRLYVLADRLQAVMLSGIILCEPPIGLPAGSSMKDATRETSP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561559</th>\n",
       "      <td>A0A1C1CI70</td>\n",
       "      <td>MQYIQTFASCAALIRDPLGHIFAGLPRASAFSAAISSNVALHPPLP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561560</th>\n",
       "      <td>A0A1C1CC49</td>\n",
       "      <td>MAAGEVPAPAKKRRIGVLTSGGDSPGMNGAVRAVVRMSIHMGCESY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561561</th>\n",
       "      <td>A0A1C1CCP4</td>\n",
       "      <td>MSPLAKLYLISCWSYIISFHLTLSILTLDMSASFPGDHFARAAKVQ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561562 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uniprot                                           sequence\n",
       "0           K0F8Z5  MSSEKIQRVGIIGAGQMGAGIAEVCARAHVDVLVYEQTRELAAAGR...\n",
       "1           K0F1Z7  MTRHVDVLIIGAGLSGIGMACHLTREQTGRSYAILERRAAIGGTWD...\n",
       "2           K0EI02  MPKARATALITAALIVVVLVAGCTRLVDGRAVSIYDDPFKVAGLPT...\n",
       "3           K0EPK0  MYSPIEDWDTDEVWMFLMQYANPWGVSNKDLLTMYQGASADSECPL...\n",
       "4           K0EQ80  MTEASADAAGARRRRNRDIAGRHVLITGASSGIGRAAAIAVAGKGA...\n",
       "...            ...                                                ...\n",
       "561557  A0A1C1CCI4  MGSIPSDQAVAPPPSTTTYNIASIPADGIGPEVITAGINVLNTLSR...\n",
       "561558  A0A1C1D2I0  MEMQLRLYVLADRLQAVMLSGIILCEPPIGLPAGSSMKDATRETSP...\n",
       "561559  A0A1C1CI70  MQYIQTFASCAALIRDPLGHIFAGLPRASAFSAAISSNVALHPPLP...\n",
       "561560  A0A1C1CC49  MAAGEVPAPAKKRRIGVLTSGGDSPGMNGAVRAVVRMSIHMGCESY...\n",
       "561561  A0A1C1CCP4  MSPLAKLYLISCWSYIISFHLTLSILTLDMSASFPGDHFARAAKVQ...\n",
       "\n",
       "[561562 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniprot_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4a228",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 30px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-success\"> New dataset</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3e51f",
   "metadata": {},
   "source": [
    "In order to exploit the data show above, we first extracted the sequences corresponding to the uniprot codes from the dataset \"uniprot_seq\". Then, thanks to the differents features provided in the original dataset we were able to reconstruct the sequence after mutation. \n",
    "Moreover, for each protein we have kept in the last column: the original amino acid, the amino acid that replaced it and finally the position of the mutation in the sequence. This column allowed us to further analyze the performance of our models to see if there was a correlation between a good prediction and the mutated amino acid. \n",
    "Finally, the y column corresponds to the label of our model. A 1 means that the mutation had no effect and a 0 the opposite. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af33ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW = \"data/extracted_data/\"\n",
    "\n",
    "TRAIN_600 = NEW + \"train_600.csv\"\n",
    "TRAIN_215 = NEW + \"train_215.csv\"\n",
    "VAL_600 = NEW + \"val_600.csv\"\n",
    "VAL_215 = NEW + \"val_215.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1eacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_600 = pd.read_csv(TRAIN_600)\n",
    "data_val_600 = pd.read_csv(VAL_600)\n",
    "data_train_215 = pd.read_csv(TRAIN_215)\n",
    "data_val_215 = pd.read_csv(VAL_215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31f6d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>sequence_mutated</th>\n",
       "      <th>sequence_mask</th>\n",
       "      <th>Y</th>\n",
       "      <th>amino_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEAPLVSLDEEFEDLRPSCSEDPEEKPQCFYGSSPHHLEDPSLSEL...</td>\n",
       "      <td>MEAPLVSLDEEFEDLRPSCSEDPEEKPQCFYGSSPHHLEDPSLSEL...</td>\n",
       "      <td>MEAPLVSLDEEFEDLRPSCSEDPEEKPQCFYGSSPHHLEDPSLSEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>('K', 'A', 264)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGRTFIHASKIKHAARKRKHHSNFRTLIKLLNNDAYKIESSKPLKN...</td>\n",
       "      <td>MGRTFIHASKIKHAARKRKHHSNFRTLIKLLNNDAYKIESSKPLKN...</td>\n",
       "      <td>MGRTFIHASKIKHAARKRKHHSNFRTLIKLLNNDAYKIESSKPLKN...</td>\n",
       "      <td>1</td>\n",
       "      <td>('W', 'A', 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNKTAIALLALLASSASLAATPWQKITQPVPGSAQSIGSFSNGCIV...</td>\n",
       "      <td>MNKTAIALLALLASSASLAATPWQKITQPVPGSAQSIGSFSNGCIV...</td>\n",
       "      <td>MNKTAIALLALLASSASLAATPWQKITQPVPGSAQSIGSFSNGCIV...</td>\n",
       "      <td>0</td>\n",
       "      <td>('H', 'A', 113)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MASSTTRGPRVSDLFSGLPPAVTTPANQSAEASAGNGSVAGADAPA...</td>\n",
       "      <td>MASSTTRGPRVSDLFSGLPPAVTTPANQSAEASAGNGSVAGADAPA...</td>\n",
       "      <td>MASSTTRGPRVSDLFSGLPPAVTTPANQSAEASAGNGSVAGADAPA...</td>\n",
       "      <td>1</td>\n",
       "      <td>('T', 'A', 365)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...</td>\n",
       "      <td>MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...</td>\n",
       "      <td>MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...</td>\n",
       "      <td>0</td>\n",
       "      <td>('E', 'Q', 59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>MVNPTTSEVQPTMGVKIFSAGVSACLADIITFPLDTAKVRLQIQGE...</td>\n",
       "      <td>MVNPTTSEVQPTMGVKIFSAGVSAALADIITFPLDTAKVRLQIQGE...</td>\n",
       "      <td>MVNPTTSEVQPTMGVKIFSAGVSA?LADIITFPLDTAKVRLQIQGE...</td>\n",
       "      <td>1</td>\n",
       "      <td>('C', 'A', 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>MSTRTPSSSSSRLMLTIGLCFLVALMEGLDLQAAGIAAGGIAQAFA...</td>\n",
       "      <td>MSTRTPSSSSSRLMLTIGLCFLVALMEGLDLQAAGIAAGGIAQAFA...</td>\n",
       "      <td>MSTRTPSSSSSRLMLTIGLCFLVALMEGLDLQAAGIAAGGIAQAFA...</td>\n",
       "      <td>0</td>\n",
       "      <td>('D', 'A', 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>MANYFNTLNLRQQLAQLGKCRFMGRDEFADGASYLQGKKVVIVGCG...</td>\n",
       "      <td>MANYFNTLNLRQQLAQLGKCRFMGRDEFADGASYLQGKKVVIVGCG...</td>\n",
       "      <td>MANYFNTLNLRQQLAQLGKCRFMGRDEFADGASYLQGKKVVIVGCG...</td>\n",
       "      <td>0</td>\n",
       "      <td>('A', 'S', 71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>MAQIFNPNPGNTLDTVANALKEQANAANKDVNDAIKALQGTDNADN...</td>\n",
       "      <td>MAQIFNPNPGNTLDTVANALKEQANAANKDVNDAIKALQGTDNADN...</td>\n",
       "      <td>MAQIFNPNPGNTLDTVANALKEQANAANKDVNDAIKALQGTDNADN...</td>\n",
       "      <td>0</td>\n",
       "      <td>('D', 'V', 76)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>MMSEQDLADVVQIAVEDLSPDHPVVLENHVVTDDDEPALKRQRLEI...</td>\n",
       "      <td>MMSEQDLADVVQIAVEDLSPDHPVVLENHVVTDDDEPALKRQRLEI...</td>\n",
       "      <td>MMSEQDLADVVQIAVEDLSPDHPVVLENHVVTDDDEPALKRQRLEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>('S', 'A', 349)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sequence  \\\n",
       "0     MEAPLVSLDEEFEDLRPSCSEDPEEKPQCFYGSSPHHLEDPSLSEL...   \n",
       "1     MGRTFIHASKIKHAARKRKHHSNFRTLIKLLNNDAYKIESSKPLKN...   \n",
       "2     MNKTAIALLALLASSASLAATPWQKITQPVPGSAQSIGSFSNGCIV...   \n",
       "3     MASSTTRGPRVSDLFSGLPPAVTTPANQSAEASAGNGSVAGADAPA...   \n",
       "4     MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...   \n",
       "...                                                 ...   \n",
       "4495  MVNPTTSEVQPTMGVKIFSAGVSACLADIITFPLDTAKVRLQIQGE...   \n",
       "4496  MSTRTPSSSSSRLMLTIGLCFLVALMEGLDLQAAGIAAGGIAQAFA...   \n",
       "4497  MANYFNTLNLRQQLAQLGKCRFMGRDEFADGASYLQGKKVVIVGCG...   \n",
       "4498  MAQIFNPNPGNTLDTVANALKEQANAANKDVNDAIKALQGTDNADN...   \n",
       "4499  MMSEQDLADVVQIAVEDLSPDHPVVLENHVVTDDDEPALKRQRLEI...   \n",
       "\n",
       "                                       sequence_mutated  \\\n",
       "0     MEAPLVSLDEEFEDLRPSCSEDPEEKPQCFYGSSPHHLEDPSLSEL...   \n",
       "1     MGRTFIHASKIKHAARKRKHHSNFRTLIKLLNNDAYKIESSKPLKN...   \n",
       "2     MNKTAIALLALLASSASLAATPWQKITQPVPGSAQSIGSFSNGCIV...   \n",
       "3     MASSTTRGPRVSDLFSGLPPAVTTPANQSAEASAGNGSVAGADAPA...   \n",
       "4     MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...   \n",
       "...                                                 ...   \n",
       "4495  MVNPTTSEVQPTMGVKIFSAGVSAALADIITFPLDTAKVRLQIQGE...   \n",
       "4496  MSTRTPSSSSSRLMLTIGLCFLVALMEGLDLQAAGIAAGGIAQAFA...   \n",
       "4497  MANYFNTLNLRQQLAQLGKCRFMGRDEFADGASYLQGKKVVIVGCG...   \n",
       "4498  MAQIFNPNPGNTLDTVANALKEQANAANKDVNDAIKALQGTDNADN...   \n",
       "4499  MMSEQDLADVVQIAVEDLSPDHPVVLENHVVTDDDEPALKRQRLEI...   \n",
       "\n",
       "                                          sequence_mask  Y       amino_info  \n",
       "0     MEAPLVSLDEEFEDLRPSCSEDPEEKPQCFYGSSPHHLEDPSLSEL...  1  ('K', 'A', 264)  \n",
       "1     MGRTFIHASKIKHAARKRKHHSNFRTLIKLLNNDAYKIESSKPLKN...  1   ('W', 'A', 75)  \n",
       "2     MNKTAIALLALLASSASLAATPWQKITQPVPGSAQSIGSFSNGCIV...  0  ('H', 'A', 113)  \n",
       "3     MASSTTRGPRVSDLFSGLPPAVTTPANQSAEASAGNGSVAGADAPA...  1  ('T', 'A', 365)  \n",
       "4     MRHGDISSSNDTVGVAVVNYKMPRLHTAAEVLDNARKIAEMIVGMK...  0   ('E', 'Q', 59)  \n",
       "...                                                 ... ..              ...  \n",
       "4495  MVNPTTSEVQPTMGVKIFSAGVSA?LADIITFPLDTAKVRLQIQGE...  1   ('C', 'A', 25)  \n",
       "4496  MSTRTPSSSSSRLMLTIGLCFLVALMEGLDLQAAGIAAGGIAQAFA...  0   ('D', 'A', 75)  \n",
       "4497  MANYFNTLNLRQQLAQLGKCRFMGRDEFADGASYLQGKKVVIVGCG...  0   ('A', 'S', 71)  \n",
       "4498  MAQIFNPNPGNTLDTVANALKEQANAANKDVNDAIKALQGTDNADN...  0   ('D', 'V', 76)  \n",
       "4499  MMSEQDLADVVQIAVEDLSPDHPVVLENHVVTDDDEPALKRQRLEI...  1  ('S', 'A', 349)  \n",
       "\n",
       "[4500 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5adcbb",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 40px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-danger\">2 |</span></b> Residual NN and CNN  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e3175",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 30px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-success\">2.1 |</span></b> Preprocessing </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f7830",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.1.1 |</span></b> Integer encoding </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83b301",
   "metadata": {},
   "source": [
    "There are 20 different amino acids that can compose our sequences. For each amino acid, an integer has been associated. The sequence of amino acids has been transformed into a sequence of integers.\n",
    "First we create a dictionary that assigns to each amino acid an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52813eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}\n",
      "Dict Length: 20\n"
     ]
    }
   ],
   "source": [
    "codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "def create_dict(codes):\n",
    "    char_dict = {}\n",
    "    for index, val in enumerate(codes):\n",
    "        char_dict[val] = index+1\n",
    "\n",
    "    return char_dict\n",
    "\n",
    "char_dict = create_dict(codes)\n",
    "\n",
    "print(char_dict)\n",
    "print(\"Dict Length:\", len(char_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce60bdfd",
   "metadata": {},
   "source": [
    "This function converts each amino acid sequence into a series of integers as defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa87b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encoding(seq):\n",
    "    \"\"\"\n",
    "    - Encodes code sequence to integer values.\n",
    "    - 20 common amino acids are taken into consideration\n",
    ".\n",
    "    \"\"\"\n",
    "    seq_encode = []\n",
    "    for code in seq:\n",
    "        seq_encode.append(char_dict.get(code, 0))\n",
    "\n",
    "    return seq_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e6f15",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.1.2 |</span></b> Padding the sequence </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da36ad1",
   "metadata": {},
   "source": [
    "This function takes a sequence and the maximum length value (in our case the value is either 215 or 600). If the length of the sequence is less than the maximum length then it adds zeros on both sides of the sequence so that the length of the sequences is homogeneous in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24605ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_len):\n",
    "    \n",
    "    if len(seq) < max_len:\n",
    "        num_add = max_len - len(seq)\n",
    "        each_side = int(num_add/2)\n",
    "        if ( each_side * 2 != num_add): \n",
    "            left = each_side\n",
    "            right = each_side + 1 \n",
    "        else : \n",
    "            left = each_side\n",
    "            right = each_side\n",
    "        out = np.pad(seq, (left, right))\n",
    "    else:\n",
    "        out = seq\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cbed4",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.1.3 |</span></b> One hot encoding </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e7452",
   "metadata": {},
   "source": [
    "Finally we transform the sequence into its corresponding one hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbd0ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_one_hot(seq, num_values):\n",
    "    one_hot_encode = []\n",
    "    for s in seq:\n",
    "\n",
    "        arr = np.zeros(num_values, dtype = int)\n",
    "        if (s == 0): \n",
    "            arr[s] = 0\n",
    "        else : \n",
    "            arr[s] = 1\n",
    "        one_hot_encode.append(arr)\n",
    "        \n",
    "    return np.array(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e53bc",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Function encode </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b240553",
   "metadata": {},
   "source": [
    "This function gathers the three functions evoked previously.\n",
    "We can directly provide it with an input amino acid sequence and the maximum length set in our dataset and it returns the corresponding one hot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b29476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_len):\n",
    "    if len(seq) < max_len:\n",
    "        num_add = max_len - len(seq)\n",
    "        each_side = int(num_add/2)\n",
    "        if ( each_side * 2 != num_add): \n",
    "            left = each_side\n",
    "            right = each_side + 1 \n",
    "        else : \n",
    "            left = each_side\n",
    "            right = each_side\n",
    "        out = np.pad(seq, (left, right))\n",
    "    else:\n",
    "        out = seq\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f451d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(seq, max_len): \n",
    "    num_values = 21 \n",
    "    temp = integer_encoding(seq)\n",
    "\n",
    "    temp = pad_seq(temp,max_len)\n",
    "\n",
    "    one_hot_seq = seq_to_one_hot(temp, num_values)\n",
    "\n",
    "    return one_hot_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9447f738",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 30px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-success\"> 2.2 |</span></b> Classification technique : Residual Neural Network </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c33581",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.2.1 |</span></b> Custom Dataset and Data Loader </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13acb2b",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Custom Dataset </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bd204",
   "metadata": {},
   "source": [
    "Creation of a ProteinDataset class. It allows to transform the mutated and non-mutated sequences of our inputs into one hot encoding for all our datasets. Moreover, the two sequences once transformed are concatenated : they form the input of our model. Our data are also transformed into tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1fe44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom_data= transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1127e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, max_seq, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.max_seq = max_seq\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        seq_, seq_mut, label = row['sequence'], row['sequence_mutated'], row['Y']\n",
    "        seq, seq_mut = encode(seq_, self.max_seq), encode(seq_mut, self.max_seq)\n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "            seq_mut = self.transform(seq_mut)\n",
    "        inputs = torch.cat((seq, seq_mut), axis = 0)  \n",
    "        inputs = inputs.float()\n",
    "\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f32690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_600 = 600\n",
    "SEQUENCE_215 = 215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e1876e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_600_ds = ProteinDataset(data_train_600, TRAIN_600, SEQUENCE_600, transform=transfrom_data)\n",
    "data_val_600_ds = ProteinDataset(data_val_600, VAL_600, SEQUENCE_600, transform=transfrom_data)\n",
    "\n",
    "data_train_215_ds = ProteinDataset(data_train_215, TRAIN_215, SEQUENCE_215, transform=transfrom_data)\n",
    "data_val_215_ds = ProteinDataset(data_val_215, VAL_215, SEQUENCE_215, transform=transfrom_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "591e29bd",
   "metadata": {},
   "source": [
    "### Import cuts of the datset\n",
    "\n",
    "For cut_5, we keep only the 5 amino acids on the left of the mutation and the 5 amino acids on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d76942",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_CUT_5 = NEW + \"val_cut_5.csv\"\n",
    "VAL_CUT_10 = NEW + \"val_cut_10.csv\"\n",
    "VAL_CUT_20 = NEW + \"val_cut_20.csv\"\n",
    "VAL_CUT_50 = NEW + \"val_cut_50.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_cut_5 = pd.read_csv(VAL_CUT_5)\n",
    "data_val_cut_10 = pd.read_csv(VAL_CUT_10)\n",
    "data_val_cut_20 = pd.read_csv(VAL_CUT_20)\n",
    "data_val_cut_50 = pd.read_csv(VAL_CUT_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_cut_5_ds = ProteinDataset(data_val_cut_5, VAL_CUT_5, SEQUENCE_215, transform=transfrom_data)\n",
    "data_val_cut_10_ds = ProteinDataset(data_val_cut_10, VAL_CUT_10, SEQUENCE_215, transform=transfrom_data)\n",
    "data_val_cut_20_ds = ProteinDataset(data_val_cut_20, VAL_CUT_20, SEQUENCE_215, transform=transfrom_data)\n",
    "data_val_cut_50_ds = ProteinDataset(data_val_cut_50, VAL_CUT_50, SEQUENCE_215, transform=transfrom_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a45ac7",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Data Loader</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ae2a0",
   "metadata": {},
   "source": [
    "Then we use the Dataloader functionality of pytorch.\n",
    "That allows you to efficiently load and preprocess a dataset for training or evaluation. It takes a dataset and a batch size as input and returns an iterator over the dataset that returns a batch of data on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa198449",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7751f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_600_dl = DataLoader(data_train_600_ds, batch_size)\n",
    "data_val_600_dl = DataLoader(data_val_600_ds, batch_size = 1)\n",
    "\n",
    "data_train_215_dl = DataLoader(data_train_215_ds, batch_size  = 1)\n",
    "data_val_215_dl = DataLoader(data_val_215_ds, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1514461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation sets for cuts of teh sequence\n",
    "data_val_cut_5_dl = DataLoader(data_val_cut_5_ds, batch_size = 1)\n",
    "data_val_cut_10_dl = DataLoader(data_val_cut_10_ds, batch_size = 1)\n",
    "data_val_cut_20_dl = DataLoader(data_val_cut_20_ds, batch_size = 1)\n",
    "data_val_cut_50_dl = DataLoader(data_val_cut_50_ds, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63c7a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 600, 21])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(iter(data_train_600_dl))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef023ded",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.2.2 |</span></b> Define the model </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be0ed581",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, d_rate):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 1, dilation = d_rate, padding = 'same'), \n",
    "                        nn.BatchNorm2d(in_channels), \n",
    "                        nn.ReLU())\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm = nn.BatchNorm2d(in_channels)\n",
    "    def forward(self, x):\n",
    "        residual = x \n",
    "        x = self.relu(self.batch_norm(x))\n",
    "        out = self.conv1(x)\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97200921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(ResidualNN, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 16, kernel_size = 1)\n",
    "        self.res1 = ResidualBlock(in_channels = 16, out_channels = 16, d_rate = 2 )\n",
    "        self.res2 = ResidualBlock(in_channels = 16, out_channels = 16, d_rate = 4 )\n",
    "        self.pool = nn.MaxPool2d(3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(22400, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.dropout(self.pool(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        outputs = self.soft(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943367e",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.2.3 |</span></b> Define the loss function, the optimizer and the hyperparametre </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfaead4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "009042c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD( model.parameters(), lr = 0.0001, momentum = 0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience= 5,\n",
    "                                                 threshold=0.0001, threshold_mode='rel', cooldown=0,\n",
    "                                                 min_lr=0, eps=1e-05, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f004a",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.2.4 |</span></b> Training </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3bd80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b7b3e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x7952 and 22400x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1760\\2645953849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1760\\3770343731.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x7952 and 22400x120)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    training_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "  \n",
    "    for i, data in tqdm(enumerate(data_train_215_dl, 0)):\n",
    "\n",
    "        \n",
    "        inputs, labels = data\n",
    "        labels = labels.long()\n",
    "        model.train()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        #print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()                                                  # Update parameters based on gradients.\n",
    "\n",
    "        # print statistics\n",
    "            # to print the training loss each iteration\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        \n",
    "        if i % 100 == 99:    # print mean of the loss every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] Loss training: {training_loss / 100:.3f}')\n",
    "            training_loss = 0.0\n",
    "            \n",
    "    # validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "           \n",
    "    with torch.no_grad():\n",
    "        counter = 0\n",
    "        for i, data in tqdm(enumerate(data_val_215_dl, 0)):\n",
    "            counter += 1\n",
    "            \n",
    "            model.eval()\n",
    "            inputs, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            validation_loss += val_loss.item()                \n",
    "    \n",
    "    last_val = validation_loss / counter\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] Loss_validation: {validation_loss / counter:.3f}')\n",
    "    print(f'Accuracy of the network on the validation set: {100 * correct // total} %')   \n",
    "\n",
    "        \n",
    "    #scheduler \n",
    "    scheduler.step(last_val)\n",
    "    print('Epoch {}, lr {}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b828934",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"ResidualNN_215.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa40ef6",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.2.5 |</span></b> Testing </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c86f4",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Test on dataset with length less than 600 </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3a17638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualNN(\n",
       "  (conv1): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (res1): ResidualBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, dilation=(2, 2))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res2): ResidualBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, dilation=(4, 4))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=22400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"ResidualNN_600.pth\"\n",
    "\n",
    "model = ResidualNN( )\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb978a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_val): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    actual = []\n",
    "    predicted = []\n",
    "\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_val):\n",
    "            inputs, labels = data\n",
    "\n",
    "            #print(labels)\n",
    "            actual.append(labels.numpy()[-1])\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(inputs)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            predicted.append(pred.numpy()[-1])\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "    confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "    make_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e724a17",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Test on dataset with length less than 215 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"ResidualNN_215.pth\"\n",
    "\n",
    "model = ResidualNN()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f894fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(data_val_215_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eda249",
   "metadata": {},
   "source": [
    "#  <style> \n",
    "    .ma-classe {\n",
    "    font-size: 30px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-success\"> 2.3 |</span></b> Classification technique : Convolutional Neural Network </div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b68efc1",
   "metadata": {},
   "source": [
    "### Import the data\n",
    "\n",
    "Here I will preprocess the data to use it directly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0a45ac7",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\"> 2.3.1 | Data Loader</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b5ae2a0",
   "metadata": {},
   "source": [
    "We use the same input format as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa198449",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7751f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_600_dl = DataLoader(data_train_600_ds, batch_size)\n",
    "data_val_600_dl = DataLoader(data_val_600_ds, batch_size = 1)\n",
    "\n",
    "data_train_215_dl = DataLoader(data_train_215_ds, batch_size  = 1)\n",
    "data_val_215_dl = DataLoader(data_val_215_ds, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c7a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 600, 21])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(iter(data_train_600_dl))\n",
    "inputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef023ded",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.3.2 |</span></b> Define the model </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b6707f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Function to calculate the output size of a CNN layer\n",
    "# before making it an input into the linear layer\n",
    "\n",
    "def findConv2dOutShape(hin,win,conv,pool=0):\n",
    "    # get conv arguments\n",
    "    kernel_size=conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "\n",
    "    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "\n",
    "    if pool:\n",
    "        hout/=pool\n",
    "        wout/=pool\n",
    "    return int(hout),int(wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be0ed581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Neural Network\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    # Network Initialisation\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "    \n",
    "        Cin,Hin,Win=params[\"shape_in\"]\n",
    "        init_f=params[\"initial_filters\"] \n",
    "        num_fc1=params[\"num_fc1\"]  \n",
    "        num_classes=params[\"num_classes\"] \n",
    "        self.dropout_rate=params[\"dropout_rate\"] \n",
    "        \n",
    "        # Convolution Layers\n",
    "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3, stride=2)\n",
    "        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n",
    "        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3, stride=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv2)\n",
    "        \n",
    "        # compute the flatten size\n",
    "        self.num_flatten=h*w*2*init_f\n",
    "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "        \n",
    "        # Convolution & Pool Layers\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.relu(self.conv2(X))\n",
    "\n",
    "        X = X.view(X.size(0), -1)\n",
    "        \n",
    "        X = F.relu(self.fc1(X))\n",
    "        X=F.dropout(X, self.dropout_rate)\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97200921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(ResidualNN, self).__init__()  # just run the init of parent class (nn.Module)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 16, kernel_size = 1)\n",
    "        self.res1 = ResidualBlock(in_channels = 16, out_channels = 16, d_rate = 2 )\n",
    "        self.res2 = ResidualBlock(in_channels = 16, out_channels = 16, d_rate = 4 )\n",
    "        self.pool = nn.MaxPool2d(3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(22400, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.dropout(self.pool(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        outputs = self.soft(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f4867ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(2, 90, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv2): Conv2d(90, 180, kernel_size=(3, 3), stride=(3, 3))\n",
      "  (fc1): Linear(in_features=53460, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f943367e",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.3.3 |</span></b> Define the loss function, the optimizer and the hyperparametre </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfaead4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Predefined Parameters\n",
    "params_model={\n",
    "        \"shape_in\": tuple(inputs.shape[1:]), \n",
    "        \"initial_filters\": 90,    \n",
    "        \"num_fc1\": 1000,\n",
    "        \"dropout_rate\": 0.25,\n",
    "        \"num_classes\": 2}\n",
    "\n",
    "# Create instantiation of Network class\n",
    "cnn_model = Network(params_model)\n",
    "\n",
    "# define computation hardware approach (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = cnn_model.to(device)\n",
    "loss_func = nn.NLLLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9630cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "854f004a",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.3.4 |</span></b> Training </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "875b699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3bd80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Helper Functions'''\n",
    "\n",
    "# Function to get the learning rate\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "# Function to compute the loss value per batch of data\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "\n",
    "    loss = loss_func(output, target) # get loss\n",
    "    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n",
    "    #print(\"pred : \", pred[:,0])\n",
    "    #print(\"target : \", target)\n",
    "    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n",
    "    #print('acc : ', acc)\n",
    "    #print('f1 : ', f1)\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "# Compute the loss value & performance metric for the entire dataset (epoch)\n",
    "def loss_epoch(model,loss_func,dataset_dl,check=False,opt=None):\n",
    "    \n",
    "    run_loss=0.0 \n",
    "    t_metric=0.0\n",
    "    acc_metric=0.0\n",
    "    f1_metric=0.0\n",
    "\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "\n",
    "    # internal loop over dataset\n",
    "    for xb, yb in tqdm(dataset_dl):\n",
    "        # move batch to device\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb) # get model output\n",
    "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # get loss per batch\n",
    "        run_loss+=loss_b        # update running loss\n",
    "\n",
    "        if metric_b is not None: # update running metric\n",
    "            t_metric+=metric_b\n",
    "            \n",
    "\n",
    "        # break the loop in case of sanity check\n",
    "        if check is True:\n",
    "            break\n",
    "    \n",
    "    loss=run_loss/float(len_data)  # average loss value\n",
    "    metric=t_metric/float(len_data) # average metric value\n",
    "    \n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b7b3e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_val(model, params,verbose=True):\n",
    "    \n",
    "    # Get the parameters\n",
    "    epochs=params[\"epochs\"]\n",
    "    loss_func=params[\"f_loss\"]\n",
    "    opt=params[\"optimiser\"]\n",
    "    train_dl=params[\"train\"]\n",
    "    val_dl=params[\"val\"]\n",
    "    check=params[\"check\"]\n",
    "    lr_scheduler=params[\"lr_change\"]\n",
    "    weight_path=params[\"weight_path\"]\n",
    "    \n",
    "    loss_history={\"train\": [],\"val\": []} # history of loss values in each epoch\n",
    "    metric_history={\"train\": [],\"val\": []} # histroy of metric values in each epoch\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # a deep copy of weights for the best performing model\n",
    "    best_loss=float('inf') # initialize best loss to a large value\n",
    "\n",
    "\n",
    "    # first step\n",
    "    train_loss, train_metric=loss_epoch(model,loss_func,train_dl,check,opt)\n",
    "    val_loss, val_metric=loss_epoch(model,loss_func,val_dl,check)\n",
    "    metric_history[\"train\"].append(train_metric)\n",
    "    metric_history[\"val\"].append(val_metric)\n",
    "    \n",
    "    # main loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        \n",
    "        ''' Get the Learning Rate '''\n",
    "        current_lr=get_lr(opt)\n",
    "        if(verbose):\n",
    "            print('Epoch {}/{}, current lr={}'.format(epoch, epochs, current_lr))\n",
    "        \n",
    "        ''' Train the Model on the Training Set '''\n",
    "        model.train()\n",
    "        train_loss, train_metric=loss_epoch(model,loss_func,train_dl,check,opt)\n",
    "\n",
    "        ''' Collect loss and metric for training dataset ''' \n",
    "        loss_history[\"train\"].append(train_loss)\n",
    "        metric_history[\"train\"].append(train_metric)\n",
    "        \n",
    "        ''' Evaluate model on validation dataset '''\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric=loss_epoch(model,loss_func,val_dl,check)\n",
    "        \n",
    "        # store best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # store weights into a local file\n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "            if(verbose):\n",
    "                print(\"Copied best model weights!\")\n",
    "        \n",
    "        # collect loss and metric for validation dataset\n",
    "        loss_history[\"val\"].append(val_loss)\n",
    "        metric_history[\"val\"].append(val_metric)\n",
    "        \n",
    "        # learning rate schedule\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            if(verbose):\n",
    "                print(\"Loading best model weights!\")\n",
    "            model.load_state_dict(best_model_wts) \n",
    "\n",
    "        if(verbose):\n",
    "            print(f\"train loss: {train_loss:.6f}, val loss: {val_loss:.6f}\")\n",
    "            print(\"-\"*10) \n",
    "        \n",
    "        if(val_loss>0.87):\n",
    "            break\n",
    "        \n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    torch.save(model.state_dict(), \"model_X\")\n",
    "        \n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97917700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 123/1125 [01:22<11:03,  1.51it/s]"
     ]
    }
   ],
   "source": [
    "params_train={\n",
    " \"train\": data_train_600_dl,\"val\": data_val_600_dl,\n",
    " \"epochs\": 10,\n",
    " \"optimiser\": optim.Adam(cnn_model.parameters(),\n",
    "                         lr=3e-4),\n",
    " \"lr_change\": ReduceLROnPlateau(opt,\n",
    "                                mode='min',\n",
    "                                factor=0.5,\n",
    "                                patience=20,\n",
    "                                verbose=1),\n",
    " \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n",
    " \"weight_path\": \"weights.pt\",\n",
    " \"check\": False, \n",
    "}\n",
    "\n",
    "''' Actual Train / Evaluation of CNN Model '''\n",
    "# train and validate the model\n",
    "cnn_model,loss_hist,metric_hist=train_val(cnn_model,params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation Progress\n",
    "epochs=params_train[\"epochs\"]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2,subplot_titles=['lost_hist','metric_hist'])\n",
    "fig.add_trace(go.Scatter(x=[*range(0,epochs+1)], y=loss_hist[\"train\"],name='loss_hist[\"train\"]'),row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=[*range(0,epochs+1)], y=loss_hist[\"val\"],name='loss_hist[\"val\"]'),row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=[*range(0,epochs+1)], y=metric_hist[\"train\"],name='metric_hist[\"train\"]'),row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=[*range(0,epochs+1)], y=metric_hist[\"val\"],name='metric_hist[\"val\"]'),row=1, col=2)\n",
    "fig.update_layout(template='plotly_white');fig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0},height=300)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa40ef6",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-info\">2.3.5 |</span></b> Testing </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c86f4",
   "metadata": {},
   "source": [
    "# <style> \n",
    "    .ma-classe {\n",
    "    font-size: 10 px;\n",
    "}\n",
    "</style>\n",
    "<div class=\"alert alert-warning\">  Test on dataset with length less than 600 </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a17638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualNN(\n",
       "  (conv1): Conv2d(2, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (res1): ResidualBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, dilation=(2, 2))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (res2): ResidualBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, dilation=(4, 4))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=22400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = cnn_model\n",
    "model.load_state_dict(torch.load(\"model_2\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Helper Functions'''\n",
    "\n",
    "# Compute the prediction\n",
    "def predict_label(model, dataset_dl):\n",
    "\n",
    "\n",
    "    pred_test=np.zeros((dataset_dl.dataset.data.shape[0]))\n",
    "    label_test=np.array((pred_test))\n",
    "    print(pred_test.shape)\n",
    "\n",
    "    # internal loop over dataset\n",
    "    for i, (xb, yb, zb) in enumerate(dataset_dl):\n",
    "        # move batch to device\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb) # get model output\n",
    "        pred=output.argmax(dim=1, keepdim=True)\n",
    "        yb=yb.numpy()\n",
    "        pred=pred[:,0].numpy()\n",
    "        batch_size=len(pred)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            pred_test[i*batch_size + j]=pred[j]\n",
    "            label_test[i*batch_size + j]=yb[j]\n",
    "            print(zb)\n",
    "    \n",
    "    return pred_test, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb978a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred, y_gt, info = predict_label(model, data_val_600_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a420f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(confusion_matrix(y_true=y_gt, y_pred=pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0b2f7116b507a4e50fe5a1a9ad7eb2c67c50ab7d1f4b632a658c72676554ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
